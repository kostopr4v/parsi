{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nW_kEPJi_0K"
      },
      "outputs": [],
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "class Parser():\n",
        "    def __init__(self, company_name, nomin):\n",
        "        self.company = company_name\n",
        "        self.url = company_name\n",
        "        self.nomin = nomin\n",
        "        \n",
        "    def get_responce(self, ):\n",
        "        self.responce = requests.get(self.url)\n",
        "        return self.responce\n",
        "    \n",
        "    def check(self, ):\n",
        "        return self.responce.status_code == 200\n",
        "    \n",
        "    def get_industries(self, ):\n",
        "        soup = bs(self.responce.text, 'html.parser')\n",
        "        categories = []\n",
        "        for category in soup.find_all('span', 'tm-company-profile__categories-wrapper'):\n",
        "            categories.append(category.text.strip())\n",
        "        return categories\n",
        "    \n",
        "    def get_about(self):\n",
        "        soup = bs(self.responce.text, 'html.parser')\n",
        "        return soup.find('span', 'tm-company-profile__content').text\n",
        "    \n",
        "    def get_date(self, ):\n",
        "        soup = bs(self.responce.text, 'html.parser')\n",
        "        return soup.find_all('dl', 'tm-description-list tm-description-list tm-description-list_variant-columns-info')[2].dd.time.text.strip()\n",
        "    \n",
        "    def get_rating(self, ):\n",
        "        soup = bs(self.responce.text, 'html.parser')\n",
        "        return float(soup.find('span', 'tm-votes-lever__score-counter tm-votes-lever__score-counter tm-votes-lever__score-counter_rating').text.strip())\n",
        "    \n",
        "    def get_news_urls(self, ):\n",
        "        news_url = self.url.replace('profile', 'news')\n",
        "        responce = requests.get(news_url)\n",
        "        soup = bs(responce.text, 'html.parser')\n",
        "        urls = []\n",
        "        for name in soup.find_all('h2', 'tm-title tm-title_h2'):\n",
        "            try:\n",
        "                urls.append(f'https://habr.com{name.a[\"href\"]}')\n",
        "            except:\n",
        "                pass\n",
        "        return urls\n",
        "    \n",
        "    def get_news_texts(self, ):\n",
        "        urls = self.get_news_urls()\n",
        "        texts = []\n",
        "        for url in urls:\n",
        "            r = requests.get(url)\n",
        "            if r.status_code == 200:\n",
        "                soup = bs(r.text, 'html.parser')\n",
        "#                 try:\n",
        "                for i in range(1, 5):\n",
        "                    for t in soup.find_all('div', f'article-formatted-body article-formatted-body article-formatted-body_version-{i}'):\n",
        "                        texts.append(t.text)\n",
        "#                 except:\n",
        "#                     pass\n",
        "        return texts\n",
        "    \n",
        "    def get_all_info(self, ):\n",
        "        print(f'! Start parsing {self.company} !')\n",
        "        self.get_responce()\n",
        "        if self.check:\n",
        "            return {\n",
        "                'name': self.company,\n",
        "                'industries': self.get_industries(),\n",
        "                'about': self.get_about(),\n",
        "                'date': self.get_date(),\n",
        "                'rating': self.get_rating(),\n",
        "                'news': self.get_news_texts(), \n",
        "                'nomin': self.nomin\n",
        "            } \n",
        "        else:\n",
        "            return {}\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vk = Parser(company_name='https://habr.com/ru/companies/vk/profile/', nomin='vk').get_all_info()\n",
        "# sber = Parser(company_name='sberbank').get_all_info()"
      ],
      "metadata": {
        "id": "xYFVfsJTjD7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "companies = [vk, sber]\n",
        "data = {key: [] for key in vk.keys()}\n",
        "for company in companies:\n",
        "    for k, v in company.items():\n",
        "        data[k].append(v)"
      ],
      "metadata": {
        "id": "yp2EwyqdjItc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data=data)"
      ],
      "metadata": {
        "id": "Mq-0wJQUjL6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "B5TpvQJsjNkU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}